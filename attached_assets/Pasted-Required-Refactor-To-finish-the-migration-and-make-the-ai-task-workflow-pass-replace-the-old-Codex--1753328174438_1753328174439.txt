Required Refactor
To finish the migration and make the ai_task workflow pass, replace the old Codex usage in .github/scripts/codex_generate.py with the new 1.x API. A simple pattern you can follow is:

python
Copy
Edit
from openai import OpenAI

client = OpenAI()
response = client.chat.completions.create(
    model="gpt-4o-mini",
    messages=[{"role": "user", "content": prompt}],
)
Patch for .github/scripts/codex_generate.py
Below is a complete, dedented replacement for the script. It uses the OpenAI client, constructs a chat prompt, and extracts the generated code from response.choices[0].message.content:

python
Copy
Edit
#!/usr/bin/env python3
"""
Script to generate Python code from a GitHub issue description using OpenAI Chat Completions.
Reads the issue description from the ISSUE_BODY environment variable and prints
the generated code to stdout. Requires the OPENAI_API_KEY environment variable
for authentication. Avoids committing any API keys to the repository.
"""
import os
import sys
from openai import OpenAI


def main() -> None:
    """Entry point for code generation."""
    api_key = os.getenv("OPENAI_API_KEY")
    issue_body = os.getenv("ISSUE_BODY")
    if not api_key or not issue_body:
        print(
            "Error: OPENAI_API_KEY and ISSUE_BODY must be set in the environment",
            file=sys.stderr,
        )
        sys.exit(1)

    # Configure OpenAI API client
    client = OpenAI(api_key=api_key)

    # Build messages for chat completion
    messages = [
        {
            "role": "system",
            "content": (
                "You are a helpful AI developer. "
                "Generate well-structured, clean Python 3.12 code that addresses the following GitHub issue. "
                "Return only the code without any explanation."
            ),
        },
        {"role": "user", "content": f"Issue:\n{issue_body.strip()}\n\nCode:"},
    ]

    try:
        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=messages,
            max_tokens=800,
            temperature=0.0,
            n=1,
        )
    except Exception as exc:
        print(f"Error contacting OpenAI API: {exc}", file=sys.stderr)
        sys.exit(1)

    if not response.choices:
        print("Error: No code returned by Chat Completions", file=sys.stderr)
        sys.exit(1)

    code = response.choices[0].message.content.strip()

    # Strip any markdown code fences if present
    if code.startswith("```python"):
        code = code[len("```python"):].strip()
    if code.startswith("```"):
        code = code[3:].strip()
    if code.endswith("```"):
        code = code[:-3].strip()

    print(code)


if __name__ == "__main__":
    main()
Next Steps
Replace the contents of .github/scripts/codex_generate.py with the above.

Remove and reapply the ai-task label on your open issue to rerun the workflow.

If you have pinned openai to an older version anywhere, update it to openai>=1.0.0 (e.g. in a requirements.txt or pyproject.toml), since the new client is now required.

After this patch, the ai_task GitHub Actions job should no longer attempt to access deprecated classes and should proceed to generate code, run make check, and open a pull request.